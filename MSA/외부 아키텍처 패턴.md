# 외부 아키텍처 패턴

마이크로서비스 시스템을 구현하기 위한 단계들

- 인프라 구축 → 미들웨어 → 애플리케이션

| 패턴유형 | 설명 |
| --- | --- |
| 인프라 구성요소 | 마이크로 서비스를 지탱하는 하부구조 인프라를 구축하는데 필요한 구성요소 |
| 플랫폼 패턴 | 인프라 위에서 마이크로서비스의 운영과 관리를 지원하는 플랫폼 차원의 패턴 |
| 애플리케이션 패턴 | 마이크로서비스 애플리케이션을 구성하는데 필요한 패턴 |

## 1. 인프라 구성요소

### 1-1. 퍼블릭 클라우드, 베어메탈, 프라이빗 클라우드 환경

인프라 구축을 위해서는 물리적인 베어 메탈 장비를 구매하여 구축하느냐, 혹은 가상화된 환경을 선택하느냐이다.

- 가상환경에 구축하기로 했더라도 클라우드 사업자가 제공하는 퍼블릭 IaaS, PaaS를 선택할지,
- 또는 직접 구매하거나 베어 메탈 서버에 프라이빗 PaaS를 구축할지 고민해야 한다.

하지만 마이크로서비스는 어떠한 장비에도 구동될 수 있다. 특정 인프라를 고집하지 않는다.

- 하지만 베어메탈 장비로 마이크로서비스를 구동한다면 마이크로서비스마다 베어메탈 장비를 구축해야하고, 유연한 확장/축소도 기대하기 어렵다.
- 따라서 MSA를 위한 베어 메탈을 고려한다면 그것은 베어메탈에 별도의 프라이빗 클라우드 환경을 구축하는 것을 의미한다.

### 1-2 VM과 컨테이너

가상 인프라 환경을 활용하기로 했다면, `가상머신 제품`과 `컨테이너` 기반 제품 중 하나를 선택해야 한다.
<img width="593" alt="스크린샷 2023-05-02 오후 5 22 33" src="https://user-images.githubusercontent.com/97823928/235616188-e3d6a961-7498-4910-aebe-f64e6c2f0c05.png">

**가상머신**은 **하이퍼바이저**라는 소프트웨어를 통해 하나의 시스템에서 여러 개의 운영체제를 사용한다

**컨테이너**는 하이퍼바이저 없이 **컨테이너 엔진**을 사용해 가상의 격리된 공간을 생성한다.

- 가상머신은 게스트OS가 존재하는데, 이는 운영체제 패치 설치나 관련 라이브러리 설치같은 오버헤드가 지속적으로 발생한다.
- 그러므로 마이크로서비스는 컨테이너 환경이 더 적합하다.
    - 도커는 필요 라이브러리나 실행 파일을 여러 개의 레이어 이미지를 추가하거나 변경할 수 있다.

### 1-3 컨테이너 오케스트레이션

컨테이너 기술을 선택했다면, `컨테이너를 관리하기 위한 기술`이 필요하다.

- 컨테이너가 많아지면 그에 따라 컨테이너의 자동 배치 및 복제, 장애 복꾸, 확장 및 축소 등등.. 컨테이너 관리를 위한 기능이 필요해 진다 → **오케스트레이션**
- 오케스트레이션 도구로는 도커 스웜, 아파치 메소스, **쿠버네티스**가 있다.
- 쿠버네티스의 주요 기능
    - 자동화된 자원 배정 : 각 컨테이너 필요로 하는 CPU와 메머리를 쿠버네티스에 요청하면 컨테이너를 노드에 맞춰 자동으로 배치한다.
    - 셀프 치유 : 컨테이너의 이상 유무를 점검해서 실패한 경우 자동으로 교체하고 재스케쥴링
    - 수평확장 : 일정 CPU, 메모리 사용량을 초고하면 자동으로 확장
    

## 2. 플랫폼 패턴

애플리케이션이 실제로 구동되는 인프라 환경을 결정했다면, 그다음으로는 인프라 환경 위에서 애플리케이션을 운영하고 관리하는 환경을 구성해야 한다. → 특히 빌드하고 배포하는 환경

### 2-1. 개발지원 환경 : 데브옵스 인프라 구성

수많은 마이크로 서비스를 하나하나를 수동으로 빌드하고 배포한다면 비효율적이다. → 자동화환경이 필요

<img width="630" alt="스크린샷 2023-05-02 오후 5 23 01" src="https://user-images.githubusercontent.com/97823928/235616278-44f6ecae-0b94-4295-be78-003b5fa84f6c.png">

1. 개발자는 개발 환경에 애플리케이션 완성 → 컴파일 → 수동으로 테스 → 오류 수정 → 스테이징 환경에 배포
2. 개발자는 운영 환경에 배포하기 전 스테이징 환경에서 다시 수동으로 테스트
3. 오류가 발생하면 다시 개발 환경으로 돌아가서 다시 …
4. 이러한 과정이 끝나면 배포 승인을 받고, 배포 담당자가 운영환경에 배포

이러한 수동 빌드/배포 과정은 너무 많은 시간이 소요되고, 시스템 사용률이 낮은 시간이 장시간 시스템을 멈추고 배포작업을 진행해야 한다. → 마이크로 서비스는 당연히 배포가 잦기 때문에 자동화가 필수!!

자동화된 빌드나 배포를 `CI/CD`라고 한다.

- CI : 자동으로 통합, 테스트하고 그 결과를 리포트로 기록하는 확동
- CD : 실행환경에 내보내는 활동
- 
<img width="681" alt="스크린샷 2023-05-02 오후 5 23 34" src="https://user-images.githubusercontent.com/97823928/235616374-0ec0c879-bce6-48c5-bb79-8b0855f404ea.png">


1. 개발자들이 소스코드와 테스트 코드를 형상관리 시스템에 보낸다.
2. 빌드도구에서 형상관리 서버의 코드를 가져와 통합한다음 자동으로 빌드하고 테스트를 수행
3. 테스트 수행결과를 리포트 문서로 기록하고, 빌드된 소스코드를 스테이징 환경에 자동으로 배포
4. 테스터가 스테이징 환경에서 테스트를 수행 또는 빌드 및 단위 테스트 결과를 개발자가 확인하고 문제가 있다면 수정

### 2-2 빌드/배포 파이프라인 설계

보통 빌드/배포되는 과정 동안 수행해야할 태스크가 정의된 것을 빌드/배포 파이프라인이라고 한다.

전형적인 파이프라인 흐름도는 다음과 같다.

<img width="501" alt="스크린샷 2023-05-02 오후 5 23 51" src="https://user-images.githubusercontent.com/97823928/235616435-383530e1-334f-4b68-bee7-df76b72407d0.png">


- 클라우드 환경이 활성화 되기 이전에는 이런 과정에서 배포 환경이 베어 메탈 하드웨어인 경우가 있어 일부 과정에서 수동 처리가 존재했으나 최근 클라우드 같은 가상 환경이 대중화 되면서 완전히 자동화가 가능하게 되었다.
- 즉 인프라 구성을 마치 소프트웨어를 프로그래밍하는 것처럼 처리하고 소수의 인원으로 많은 컨테이너 배포 처리를 할 수 있게 되었다 → **Infrastructure as Code**

<img width="584" alt="스크린샷 2023-05-02 오후 5 24 09" src="https://user-images.githubusercontent.com/97823928/235616505-aff1d276-4561-456e-bb2b-5482a7eb5f40.png">


마이크로서비스의 배포파이프라인 설계 시 중요하게 고려해야 할 부분은 마이크로서비스의 경우 배포 파이프 라인도 마이크로서비스 별로 별도로 설계해야 지 독립적인 수정 및 배포가 가능하다는 점이다.

### 2-3. 레지스트리, 서비스 디스커버리 패턴

클라이언트가 여러개의 마이크로서비스를 호출하기 위해서는 

- 최적 경로를 찾아주는 `라우팅 기능`과 (→ **줄**(Zuul))
- 부하분산을 위한 `로드 밸런싱 기능`이 제공되어야 한다. (→ **리본** (Ribbon))

<img width="604" alt="스크린샷 2023-05-02 오후 5 24 32" src="https://user-images.githubusercontent.com/97823928/235616591-e16bb43d-9fd5-4066-a07c-ed79a766802b.png">

라우터는 최적 경로를 탐색하기 위해 서비스 명칭에 해당하는 IP주소를 알아야한다. 

- 이러한 라우팅 정보를 클라이언트가 가지고 있다면 동적으로 변경되는 백엔드의 유동 IP정보를 매번 전송받아 변경해야한다.
- 그래서 **제 3의 공간**에서 서비스 명칭과 유동적인 IP주소를 매핑해서 보관하는 것이 좋다 → 넷플릭스 OSS의 **`유레카`**

1. 각 서비스 인스턴스가 로딩될 때 자신의 서비스 이름과 할당된 IP주소를 레지스트리에 등록한다.
2. 클라이언트가 해당 서비스 명을 호출할 때 라우터가 레지스트리 서비스를 검색해 해당 서비스의 이름과 매핑된 IP 주소를 확인한 후 호출한다.
- 레지스트리 서비스는 모든 마이크로서비스의 인스턴스의 주소를 알고 있는 서비스 매핑 저장소가 된다.

### 2-4. API 게이트웨이 패턴

여러 클라이언트가 여러 개의 서버 서비스를 각각 호출하게 된다면 복잡한 호출관계가 형성될 것이다.

이러한 **서비스 단일 진입을 위한 방법**을 `API 게이트웨이 패턴`이라한다.

<img width="713" alt="스크린샷 2023-05-02 오후 5 25 02" src="https://user-images.githubusercontent.com/97823928/235616713-f8319cad-58c9-4485-8ae5-b026cdde12c9.png">

이처럼 단일 진입점을 만들어 놓으면 다양한 클라이언트에게 서로 다른 API 조합을 제공할 수도 있고, 각 서비스에 접근할 떄 필요한 인증/인가 기능도 한번에 처리할 수 있다.. 등등

### 2-5. BFF 패턴

<img width="691" alt="스크린샷 2023-05-02 오후 5 25 36" src="https://user-images.githubusercontent.com/97823928/235616858-97bb7018-a63f-4985-ba0c-851d92a6a98a.png">

최근에는  PC뿐 아니라 다양한 모바일 장비를 사용하므로 그에 따라 다양한 클라이언트가 존재한다.

→ BFF패턴은 프런트엔드 유형에 따라 진입점을 다르게 두는 패턴이다. 

- 웹을 위한 API 게이트웨이, 모바일을 위한 API 게이트웨이 등 클라이언트 종류에 따라 최적화된 처리를 수행할 수 있게 구성할 수 있다. 이로써 모바일을 위한 API만을 선택하여 제공하거나 웹을 위한 API만을 적절하게 제공할 수 있다.
- 각 프로트엔드에 관한 처리 만을 위한 BFF를 두고 이후에 통합적인 API GW를 둠으로써 공통적인 인증/인가,로깅 등의 처리를 통제하는 구조로 구성 할 수도 있다.

### 2-6. 외부 구성 저장소 패턴

클라우드 인프라의 경우 DB연결 정보, 파일 스토리지 정보 등을 애플리케이션에 포함하면 변경 시 반드시 재배포해야한다. 이 경우 서비스를 중단해야한다. → 마이크로서비스의 경우에도 자원의 설정 정보를 쉽고 일관되게 변경가능하도록 관리할 필요가 있다.

외부 저장소는 각 마이크로 서비스의 외부 환경 설정 정보를 공동으로 저장하는 백업저장소이다.

- `Config 원칙` : 배포 환경이 매번 달라지므로 환경 설정정보는 코드와 분리되어 관리되어야 한다는 원칙

### 2-7. 인증/인가 패턴

**`중앙 집중식 세션 관리`**

- 모노리스 방식에서 가장 많이 사용했던 방식은 **서버 세션에 사용자의 로그인 정보 및 권한 정보를 저장**하고 이를 통해 인증/인가를 판단하는 것
- 마이크로서비스는 사용량에 따라 수시로 수평 확장할 수 있고 로드 밸런싱이 되기 때문에 세션 데이터가 손실될 수 있다. 따라서 마이크로비스는 **공유 저장소에 세션을 저**장하고 모든 서비스가 동일한 사용자 데이터를 얻게 한다.
- 보통 세션 저장소로 레디스(Redis), 맴캐쉬드(Memcached)를 사용한다.

**`클라이언트 토큰`**

<img width="379" alt="스크린샷 2023-05-02 오후 5 25 58" src="https://user-images.githubusercontent.com/97823928/235616941-9d21ea6f-6845-405c-a0ba-5942303d7df4.png">

- 세션은 서버의 중앙에 저장되고 **토큰은 사용자의 브라우저에 저장**된다.
- 토큰은 사용자이 신원정보를 가지고 있고 서버로 요청을 보낼 때 전송되기 때문에 서버에서 인가 처리를 할 수 있다.

**`API 게이트웨이를 사용한 클라이언트 토큰`**

- 사용자 인증 프로세스는 토큰 인증 프로세스와 유사하나 API 게이트웨이가 외부 요청의 입구로 추가된다
- 또한 인증/인가에 처리를 위한 별도의 전담서비스를 만들어서 다른 서비스의 인증/인가 처리를 위임 시킬 수 있다. 이런 서비스 **Auth서비스**라 하는데 API 게이트웨이와 연동해서 인증 인가를 처리한다. Auth서비스를 사용하면 각각의 리소스 서비스가 자체적으로 인증 인가를 처리하지 않고 순수 업무처리에 집중할 수 있다.
<img width="708" alt="스크린샷 2023-05-02 오후 5 26 21" src="https://user-images.githubusercontent.com/97823928/235617023-b4f60789-52e5-42d8-89f0-0eabd4bb526c.png">


1. 클라이언트가 리소스 서비스에 접근을 요청하면 API 게이트웨이는 Auth서비스에게 포워딩한다.
2. Auth 서비스는 해당 요청이 인증된 사용자인지(인증) 해당 리소스 접근 권한이 있는지 (인가)확인하고 모두 가능하다면 리소스에 접근 가능한 증명서인 토큰을 발급한다.
3. 클라이언트는 다시 액세스 토큰을 활용하여 접근을 요청한다.
4. 그럼 각각의 리소스 서비스는 이런 요청이 액세스 토큰을 포함하고 있는지 판단하여 리소스를 허용한다

### 2-8. 서킷 브레이커 패턴

여러 서비스로 구성된 시스템에서 한 서비스에 장애가 발생했을 때 다른 서비스가 영향을 받을 수 있다.

이때 장애가 발생한 서비스를 격리해서 유연하게 처리할 수 있는 방법을 서킷 브레이커 패턴이라 한다.

서킷브레이커 패턴은 특정 서비스에 문제가 생겼을 때 다른 정상 서비스로 요청 흐름이 변경되도록 한다.

- 그러려면 서비스 상태를 실시간 관리, 시각화, 모니터링 해야하며, 장애가 감지되면 다른 서비스로 전이되지 않도록 해야한다.

### 2-9. 모니터링과 추적 패턴

서킷브레이커 패턴을 가능하게 하려면 각 마이크로 서비스의 장애를 실시간으로 감지해야하며, 서비스간의 호출이 어떤지 알아야 한다 

→ 스프링 클라우드에서는 `히스트릭스` 라이브러리를 제공하는데 이를 통해 각 요청이 차지하는 트래픽 파악 가능

→ `집킨`이라는 오픈소스는 모니터링과 함께 각 서비스의 트랜잭션 호출을 추적할 수 있다.

### 2-10. 중앙화된 로그 집계 패턴

마이크로서비스는 사용량에 따라 탄력적으로 변화하므로, 언제든지 인스턴스가 생성/삭제 될 수 있기 때문에 로컬의 로그는 초기화될 수 있다.

- 로그는 고정된 시작과 끝이 있는 것이 아니라 서비스가 실행되는 동안 계속 흐르는 흐름이다. 그리고 서비스는 스트림의 전달이나 저장에 절대 관여하지 않아야 한다.
- 왜냐하면 로그를 전달,저장처리하는 메커니즘 자체가 특정 기술,인프라에 의존될 수 밖에 없고 이런 메커니즘을 직접 마이크로서비스가 구현하면 그 유연성이 떨어지기 때문이다.
    
    → 그래서 필요한 것이 **중앙화된 로그 집계 패턴**이다. 
    
<img width="718" alt="스크린샷 2023-05-02 오후 5 26 42" src="https://user-images.githubusercontent.com/97823928/235617094-a47a7d39-41a1-4dde-bf40-4b0f22168f05.png">


마이크로서비스의 로그 수집을 위한 ELK 스택 구축 아키텍처

- 각각의 서비스에 Logstash가 설치되어 각 로그를 수집해서 레디스 저장소에 보낸다.
- 하나의 서비스에서는 Elasticsearch와 Kibana로 로그 중앙 관리 저장소와 대시보드 서비스를 구축한다.
- 그리고 레디스에서 중앙 관리 저장소에 로그를 보내게 되고 이 로그 저장소에 엘라스틱서치(Elasticsearch)엔진이 로그를 인덱싱하고 그 로그 정보가 키바나(Kibana) 대시보드를 통해 보여진다.
- 마이크로서비스의 Logstash가 바로 로그 저장소에 로그를 보낼 수 있지만 로그 스트림이 너무 몰리면 로그 저장소 서비스 역시 성능에 문제가 생기기 때문에 중간에 레디스 DB를 추가한다.

### 2-11. 서비스 메시 패턴

마이크로서비스를 연계하고 관리/운영하기 위해서는 API 게이트웨이, 서비스 레지스트리, 컨피그 서비스 등의 서비스를 별도로 각각 만들어야 하는 번거러움이 있다. 

- 기능 구현에 집중해야 해야하는 마이크로서비스 입장에서 이러한 공통기능들이 번거롭기도 하다.
- 통신 네트워크 기능을 비지니스로직 기능과 분리하여 네트워크 인프라 계층에서 수행하게 하는 서비스 메시(Service Mesh)를 선호하기도 한다.

<img width="604" alt="스크린샷 2023-05-02 오후 5 26 58" src="https://user-images.githubusercontent.com/97823928/235617137-84fb9162-4074-4c4e-a662-185ad272814e.png">


왼쪽의 스프링 클라우드,넷플릭스 OSS를 이용한 경우

- 스프링 클라우드로 기반 서비스를 먼저 구축하고
- 마이크로서비스 어플리케이션 자체도 내부 코드에 이런 관리/운영 기능을 제공하는 클라이언트 코드가 탑재 되어야 한다.

그렇지만 서비스 메시를 적용하게 되는 경우에는 

- 마이크로서비스는 순수 비지니스 로직에 집중하고
- **컨테이너에 관리/운영 기능을 제공하는 별도의 사이드카 프록시를 같이 배포**하면 된다.
- **이스티오**는 **엔보이를 통제하는 Control Plain 기능**에 의해 기존에 넷플릿스 OSS가 제공하는 관리/운영 기능을 제공한다.

<img width="647" alt="스크린샷 2023-05-02 오후 5 27 12" src="https://user-images.githubusercontent.com/97823928/235617197-392244dd-0335-4e09-87cc-d1423019cbb2.png">
쿠버네티스의 컨테이너 단위인 파드에 서비스 컨에티너와 사이드카 구현체인 엔보이 컨테이너가 함께 배포된 모습

## 3. 애플리케이션 패턴

### 3-1. UI컴포지트 패턴, 마이크로 프론트엔드

<img width="537" alt="스크린샷 2023-05-02 오후 5 27 28" src="https://user-images.githubusercontent.com/97823928/235617247-bb315fe3-e678-4ea3-bcfd-d66bfe3135fd.png">

모노리스 프런트엔드는 백엔드의 여러 API를 호출하고 조합한 후 화면으로 구성해서 보여준다.

이러한 경우 마이크로서비스 기반 시스템의 장점인 서비스의 독립적인 변경과 배포가 불가능하다.

- 변경이 필요한경우, 백엔드는 수정하여 하나의 서비스로 독립적으로 배포가 가능하지만.
- 프런트엔드는 덩어리기 떄문에 변경되지 않은 다른 기능들도 함께 빌드되고 배포해야한다.

→ 해결방안 :  UI컴포지트 패턴, 마이크로 프론트엔드

프런트엔드도 백엔드 마이크로서비스처럼 기능별로 분리하고, 이를 조합하기 위한 프레임의 형태를 부모 창을 통해 각 프런트엔드를 조합해서 동작하게 한다. 이 부모는 틀만 가지고 있고, 각 기능의 실제 표현은 

마이크로 프런트엔드 조각이 구현한다.

### 3-2. 마이크로 서비스 통신 패턴

1 ) 동기 통신 방식

<img width="605" alt="스크린샷 2023-05-02 오후 5 27 46" src="https://user-images.githubusercontent.com/97823928/235617301-3cc7b448-c0a9-4497-8d3c-ea7c497c09a0.png">

동기 호출은 클라이언트에서 서버 쪽에 존재하는 마이크로서비스 REST API를 호출할 때 기본 통신 방법이다. 

- 동기 방식은 Sync 방식이라고 하는데 동기식 호출은 요청(Request) 하면 바로 반응(Response)이 오는 방식을 말한다.

```java
그림을 보면 모바일 UI고객의 주문내역을 확인하기 위해 주문서비스에 HTTP GET 방식의 요청을 하면 
주문서비스는 고객정보를 확인하기 위해 고객서비스에 GET방식의 동기 호출을 하고 있다. 
그에 따라 바로 응답이 발생하고 성공 시 200이라는 OK 코드를 받아오는 것을 볼 수 있다. 
이렇게 바로 요청하면 응답이 바로 오는 직관적인 방식이기 때문에 가장 많이 쓰이고 구현 하기 쉽다. 
그렇지만 호출을 받은 마이크로서비스에서 장애가 생긴다면 어떨까? 
호출한 서비스는 반응이 올 때까지 기다리게 되고 반응이 오지 않으면 계속 기다리면서 재호출하게 된다.
```

- 한 서비스가 다른 서비스를 호출하여 바로 얻은 정보를 이용해 기능을 제공한다는 의미는 **그 서비스들간의 의존관계가 높다는 것을 의미한다.**
- 이런 상태의 서비스 제공은 독자적인 마이크로서비스별로의 비즈니스 기능 처리를 어렵게 한다. 그래서 이러한 장애의 파급효과 및 의존관계를 낮추기 위한 다른 통신 방법이 필요하다.

2 ) 비동기 통신 방식 

비동기식은 동기식 호출처럼 응답을 기다리지 않는다. 

- 메시지를 보낸 다음에 응답을 기다리지 않고 자신의 일을 처리한다.
- 물론 보낸 결과가 어떻게 되었는지 응답을 받지 않으니 동기식처럼 완결성을 보장할 수는 없다.
- 따라서 이를 보장하기 위한 메커니즘이 필요한데 보통 아파치 카프카(Apache Kafka), 래빗엠큐(RabbitMQ), 액티브엠큐(ActiveMQ) 같은 메시지 브로커(Message broker) 사용한다.
- 메시지 브로커에 전달할 메시지를 던지고 자신의 일을 처리하면 **메시지 브로커가 전송을 보장**하게 된다. 그런데 여러 서비스에서 던진 메시지를 처리하기 위해서는 메시지 브로커 자체에 부하가 걸릴 수가 있다. 그럴 경우 메시지 브로커는 메시지 처리 규모에 따라 확장이 가능하다.

<img width="716" alt="스크린샷 2023-05-02 오후 5 27 57" src="https://user-images.githubusercontent.com/97823928/235617333-ba81df30-41ae-47dd-bd66-546a5cd30085.png">

 

### 3-3. 저장소분리 패턴

기존 모노리스 시스템의 저장소는 통합 저장소 → 저장소는 다른 모듈에서의 호출을 허용

- 이러한 경우 아무리 여러개의 마이크로서비스로 분리하더라도, 요청사항이 증가하면 서비스는 한가하고 여러 서비스에서 호출되는 데이터베이스만 바쁘게 된다. → 스케일 아웃 기능이 소용이 없어진다!

이를 해결하기 위해

- 자신이 소유한 데이터는 다른 서비스에 노출하지 않고 API를 통해서만 접근 → 정보은닉
- 또한 저장소가 격리되어있기 떄문에 각 저장소를 자율적으로 선택 → 플리그랏


<img width="688" alt="스크린샷 2023-05-02 오후 5 28 13" src="https://user-images.githubusercontent.com/97823928/235617401-841d7d73-1596-468c-8304-47190ae1d72d.png">


그림을 통해 살펴보면 주문서비스가 주문 수행을 위해 고객 정보를 필요로 한다면, 바로 고객 테이블을 질의를 할 수 없고, 반드시 고객 서비스의 API를 통해서만 호출할 수 있다

→ 여러 개의 분산된 서비스를 걸쳐 비지니스 처리를 해야 하는 경우 **비지니스 정합성 및 데이터 일관성을 어떻게 보장할 것인가**에 대한 문제 발생

> **전통적인 분산처리 트랜잭션의 문제점**

쉽게 접근할 수 있는 방법은 여러 개의 분산된 서비스를 `하나의 일관된 트랜잭션으로 묶는 방법`이다.

- 분산 트랜잭션 처리를 위해 전통적인 방법으로 **2단계 커밋** 기법이 있다. 분산 데이터베이스 환경에서 원자성(Atomicity)을 보장하기 위해 분산 트랜잭션에 포함되어 있는 모든 노드가 Commit되거나 Rollback하는 메커니즘 이다. 그런데 이런 방법은 각각 서비스에 동시에 락인(lock in)을 걸게 되면 발생하는 퍼포먼스의 문제로 효율적인 방법이 아니다. 특히 각각의 서비스가 다른 인스턴스로 로딩되기 때문에 통제하기 어렵다. 또한 이런 방법은 서비스 각각의 저장소가 틀릴 경우에 문제가 되며 특히 몽고DB같은 No SQL저장소는 2PC 자체를 지원하지 않는다.

### 3-4. **SAGA 패턴**

사가 패턴은 여러 개의 분산된 서비스들을 하나의 트랜잭션을 묶지않고 **각 로컬 트랜잭션과 보상 트랜잭션을 이용**하여 비지니스 및 데이터 정합성을 맞춘다.

💡 일관성 유지가 필요한 트랜잭션을 모두 묶어 하나의 트랜잭션으로 처리하지 않고, **각각의 로컬 트랜잭션으로 분리하여 순차적으로 처리하는 방법**

- 로컬 트랜잭션은 자신의 데이터베이스를 업데이트한 다음에 Saga 내에 있는 다음 로컬 트랜잭션을 트리거 하는 메시지 또는 이벤트를 게시하여 데이터의 일관성을 맞춘다.
- 보상 트랜잭션은 어떤 서비스에서 트랜잭션 처리에 실패할 경우, 그 서비스의 앞선 다른 서비스에서 처리된 트랜잭션을 되돌리게 하는 트랜잭션이다.

<img width="605" alt="스크린샷 2023-05-02 오후 5 28 27" src="https://user-images.githubusercontent.com/97823928/235617433-99106755-eb95-45e3-bcfd-8227cc36955b.png">


예를 들어 하나의 업무를 가지고 생각해 보겠다. 아래 그림과 보면 주문서비스와 고객서비스가 있다. 그리고 주문 처리 시 고객의 신용한도 정보에 따라 최종 주문을 승인하는 업무가 있다. 이 두 서비스의 트랜잭션을 하나로 묶지 않고 보상 트랜잭션과 이벤트를 활용해서 처리할 수 있다.
<img width="607" alt="스크린샷 2023-05-02 오후 5 28 44" src="https://user-images.githubusercontent.com/97823928/235617484-c3a29b37-2ea7-4c43-8a8b-ac18f709e50e.png">


1. 주문 처리가 시작되면 주문 서비스는 가 주문을 생성하고 주문자정보가 담긴 ‘가 주문 생성됨’ 이벤트를 발행하고 트랜잭션을 종료한다.
2. 그러면 고객서비스가 ‘주문 생성됨’ 이벤트를 확인한 뒤, a.이벤트에 존재하는 주문자 정보로 고객의 신용한도를 조회하여 신용한도가 충족된다면 ‘신용 승인됨’ 이벤트를 발행한다. b.그리고 신용한도가 충족되지 않는다면 ‘신용한도 초과됨’ 이벤트를 발행한다.
3. 그럼 다시 주문 서비스는 고객 서비스가 발행한 이벤트를 확인하는데a. 고객서비스가 발행한 이벤트가 ‘신용 승인됨’인 경우에는 주문승인처리하고 b. ‘신용한도 초과됨’ 이벤트인 경우에는 보상트랜잭션인 주문처리취소를 수행한다. 이와 같이 하나의 큰 트랜잭션으로 묶지 않고 4개의 분리된 로컬 트랜잭션으로 비지니스의 정합성을 맞출 수 있다.

<img width="601" alt="스크린샷 2023-05-02 오후 5 29 02" src="https://user-images.githubusercontent.com/97823928/235617548-74d029f0-b689-4443-b66c-650cc3d6d53d.png">


모든 비지니스 처리가 반드시 실시간성을 요구하는 것은 아니다. 어떤 비지니스는 실시간상으로 데이터 일관성이 안 맞아도 어느 시점이 되면 일관성을 만족해도 되는 것이 있다. 

→ 이러한 개념을 **결과적 일관성(eventual consistency)** 이라고 한다. 

<img width="621" alt="스크린샷 2023-05-02 오후 5 29 16" src="https://user-images.githubusercontent.com/97823928/235617608-e231eaed-bd52-4620-9bcf-62c0b3b8434f.png">


1. 가 주문이 생성되고 ‘가 주문됨’ 이벤트를 발행한다. 주문은 독립적 로컬 트랜잭션이기 때문에 끊임없이 받을 수 있다. 주문이 몰릴 경우 주문서비스만 확장하여 가용성을 높일 수 있다.
2. ‘가 주문됨’이벤트는 메시지 브로커에 비동기로 전송된다.
3. 결제 서비스는 발행된 ‘가 주문됨’ 이벤트를 확인하여 결제서비스는 자신의 대금결제 트랜잭션을 수행하고 ‘결제 처리됨’ 이벤트를 발행한다.
4. 이메일 서비스는 ‘결제 처리됨’ 이벤트를 확인하여 주문결제완료 이메일을 사용자에게 발송한다.
5. 주문 서비스는 ‘결제 처리됨’이벤트를 확인하여 가 주문 처리되었던 주문을 최종 승인한다. 그리고 ‘최종 주문 완료됨’이벤트를 발행한다.
6. 이메일 서비스는 주문 서비스가 발행한 ‘최종 주문 완료됨’이벤트를 확인하여 최종 주문 완료됐다는 이메일을 사용자에게 발송한다.
7. 각 서비스는 해당 작업 수행하다 오류가 발생하면 마찬가지로 ‘실패 이벤트’를 발행하여 다른 서비스가 비지니스 정합성을 맞출 수 있도록 한다.
8. 이때 별도로 메시지 큐에 쌓이는 이벤트들을 모니터링 서비스와 연계해 모니터링하고 추적하여 전체적인 비지니스 정합성 여부를 관리자가 확인할 수도 있다.

### 2-4. CQRS 패턴

<img width="303" alt="스크린샷 2023-05-02 오후 5 29 32" src="https://user-images.githubusercontent.com/97823928/235617659-51440877-2577-47c8-800a-bf79b7c01895.png">

기존에는 동일한 저장소에 데이터를 넣고, 입력 조회 수정 삭제를 모두 처리하는 방식이다.

하지만 실제 업무를 살펴보면 상태를 변경하는 명령보다는 조회하는 명령이 많이 쓰인다.

→ 서비스 내에 이러한 모든 기능을 넣어두면 조회 요청 빈도가 증가함에 따라 다른 명령 기능도 확장해야 한다.
<img width="603" alt="스크린샷 2023-05-02 오후 5 29 43" src="https://user-images.githubusercontent.com/97823928/235617697-fc8c95b5-928a-4f73-8cc7-5b8956ec27e6.png">


하지만 하나의 저장소에 쓰기 모델과 일끼 모델을 분리시키거나, 아예 물리적으로 쓰기 트랜잭션용 저장소와 저장용 저장소를 따로 준비할 수 있다. → 시스템 부하 및 조회 대기 시간 감소

- 명령 측면 마이크로서비스는 입력,수정,삭제(Create, Update, Delete) 처리를 수행하고 저장소로는 쓰기에 최적화된 관계형 데이터베이스를 사용한다. 그리고 프로그램언어도 업무 규칙을 표현하기 좋은 Java 언어를 사용한다.
- 반면에 쿼리 측면의 마이크로서비스는 조회 성능이 높은 몽고디비(Mongo DB)나 일레스틱서치(Elasticsearch)와 같은 NO-SQl DB를 사용한다. 그리고 프로그램언어도 조회를 간단하게 구현할 수 있는 스크립트(Script) 기반의 노드제이에스(Node.js) 을 사용한다. 그리고 조회서비스는 사용량이 많기 때문에 스케일 아웃하여 인스턴스를 증가시켜 놓을 수 있다.

이런 구조에서는 명령 측면 서비스가 사용됨에 따라 조회측면서비스와의 데이터 일관성이 깨지게 된다. 따라서 이때 데이터 일관성 유지를 위한 이벤트 메시지 주도 아키텍처가 등장한다.

<img width="618" alt="스크린샷 2023-05-02 오후 5 29 55" src="https://user-images.githubusercontent.com/97823928/235617745-66069639-c81b-4e90-9607-d90e26263258.png">

쓰기 서비스는 저장소에 데이터를 쓰면서 저장한 내역이 담긴 이벤트를 발생시켜서 메시지브로커에 전달한다. 조회 서비스는 이러한 메시지 브로커의 이벤트를 구독하고 있다가 이벤트데이터를 가져와 자신의 데이터를 최신 상태로 동기화 시켜준다.

물론 명령 측면 서비스에 데이터가 들어간 즉시 조회 측면 서비스의 데이터가 일치할 수 없고 시간적 간격이 있을 수 있지만 어느 시점이 되면 결과적으로 일치하게 된다. 앞서 말 한 결과적 일관성(Eventual Consistency)추구하는 것이다.

**API 조합과 CQRS**

만약 저장소가 격리되어있고, 마이크로서비스마다 각기 다른 기능을 구현했다 가정하자.

이러한 경우 마이크로서비스를 여러 개 연계해서 서비스를 제공하는 경우 어떻게 해야할까?
<img width="609" alt="스크린샷 2023-05-02 오후 5 30 23" src="https://user-images.githubusercontent.com/97823928/235617836-9f7c7c41-ae4d-4316-91c5-85f6b9fa72f1.png">


API Composition 은 아래 그림과 같이 각 기능을 제공하는 마이크로서비스를 조합하는 상위의 마이크로서비스를 만들어서 조합된 기능을 제공할 수 있다. 하위 서비스는 각자 독립적인API를 제공하면서 연계API를 위해 상위서비스에 정보를 제공해 준다. 그렇지만 이런 구조는 상위 서비스가 하위 서비스에 의존하는 결과를 가져온다. 상위 서비스가 제공하는 API에 정보를 제공하는 하위 서비스 중에 하나라도 API를 변경하게 되면 상위 서비스는 따라서 변경될 수 밖에 없다

<img width="500" alt="스크린샷 2023-05-02 오후 5 30 34" src="https://user-images.githubusercontent.com/97823928/235617876-d8cf865c-74b3-40ef-aa9e-8912aeb429b3.png">

CQRS를 적용하는 것이다. 아래 그림과 같이 주문 이력을 보여주는 마이크로서비스가 필요하다고 보자. 주문 이력 마이크로서비스를 별도로 만들고 주문 이력의 세세한 원천 정보를 보유한 각 서비스도 독자적으로 자신의 서비스를 제공한다. 그리고 이 원천데이터를 보유한 복수의 마이크로서비스들은 각자의 데이터 변경 이벤트를 발행한다.

그럼 주문 이력 마이크로서비스는 이 이벤트를 구독하고 있다가 이벤트를 가져와서 조회 용 자신의 저장소에 일관성을 맞춰주고 주문 이력조회 서비스를 제공한다. 즉 조회 용 마이크로서비스를 별도 생성하고 다른 서비스로부터 비동기 이벤트로 일관성을 맞춰 줌으로써 API Composition 방식의 단점인 직접적인 의존성을 줄일 수 있는 것이다.

### 2-5. 이벤트 소싱 패턴

```java
사가 패턴 및 CQRS 패턴이 비즈니스 불일치를 피하기 위해서는 
저장소에 저장하는 것과 메시지를 보내는 것이 원자성(atomicity) 을 가져야 한다. 
즉 저장소에 저장하는 일과 메시지를 보내는 작업이 언제나 완전하게 진행되어 종료되거나 
같이 실행 되지 않아야 된다는 말이다. 
그렇지만 객체의 상태변화를 이벤트 메시지로 발행하고 또 객체 상태를 관계형 저장소를 사용하는 경우 
SQL 질의어로 변환해서 처리하는 것이 매우 번거롭고 까다롭다. 
또한 CQRS패턴으로 명령 측면과 조회측면으로 분리했더라 하더라도 
명령 측면에 추가,변경,삭제 작업이 한꺼번에 발생하기 때문에 동시 업데이트 문제가 발행할 수도 있다. 
또 메시지 처리, 명령 처리를 2가지 기능을 수행하므로 빠르지도 않다.
```

객체 상태를 데이터 모델에 맞춰 계산하게 되면 매우 느리고 복잡하다.

하지만 상태 변경 이벤트를 게산해서 데이터모델로 변경하지 않고 이벤트 저장소에 그대로 **트랜잭션을 저장**하면 된다. → 메시지 브로커와 데이터 저장소를 분리하지 않고 하나로 사용하면 된다. 복잡한 과정이 없으니 쓰기 속도가 훨씬 빠르다.

현재 시점의 상태가 필요할 때는 상태의 출발점부터 모든 기록된 상태 변경 트랜잭션을 순차적으로 계산한다.

처음부터 모든 트랜잭션을 처리하는 것이 부담된다면 매일 자정에 상태를 계산한 후 스냅샷으로 저장한 후 현 상태 정보가 필요해지면 스냅 샵(Snapshot) 이후의 트랜잭션만 처리하면 된다. 이런 방식은 특정 시점의 상태가 필요하면 재현할 수도 있기 때문에 별도의 트랜잭션 성HISTORY 로그 데이터를 쌓을 필요도 없다.

또 중요한 점은 명령 측면과 조회 측면의 서비스가 CRUD를 모두 처리할 필요없이 CR만 처리하면 된다는 것이다. 저장소에서 변경과 삭제가 발생하지 않기 때문에 명령 측면 서비스를 여러 개 확장해도 동시 업데이트 및 교착상태가 발생하지 않는다.

<img width="500" alt="스크린샷 2023-05-02 오후 5 30 49" src="https://user-images.githubusercontent.com/97823928/235617922-27ff959c-a03b-4d6a-a30b-17f3401fc3a7.png">



CRUD가 모두 발생하지 않고 CR만 사용하는 개념이라 쓰기서비스를 여러 개 확장해도 동시 업데이트 및 교착상태, 정합성 등의 문제가 발생되지 않는다. 또 저장과 동시에 그대로 메시지 형태로 메시지 브로커에 발행하여 다른 서비스에 영향을 줄 수 도 있다.

다시 정리하면 아래 그림처럼 이벤트 소싱은 모든 트랜잭션의 상태를 바로바로 계산하지 않고 별도의 이벤트 스트림으로 이벤트 스트림 저장소에 저장하는 방식이다. 이벤트 스트림 저장소는 오로지 추가만 가능하게끔 해서 계속 이벤트들이 쌓이게 만들고 실제로 내가 필요한 데이터를 구체화시키는 시점에서는 그때까지 축적된 트랜잭션을 바탕으로 그 상태를 계산하여 구성한다.

이벤트 저장소는 이벤트 데이터베이스 역할 뿐만 아니라 메시지 브로커처럼 작동한다. 이는 데이터 저장 처리 메커니즘과 메시지 큐 같은 이벤트를 전달하기 위한 메커니즘을 통합하여 복잡함을 감소시키고 특히 쓰기 성능을 최적화 한다. 또한 100%로의 정확한 감사 로깅을 제공하고 객체의 예전 상태를 재구성하는 것이 간단해 지며 외부 어플리케이션도 이벤트 전달도 간편하다.
